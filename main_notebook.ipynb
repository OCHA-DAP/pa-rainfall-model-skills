{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AA_DATA_DIR'] = \"/home/daniele/Documents/CHD/Python_projects/pa-aa-toolbox-folder/\"\n",
    "os.environ['IRI_AUTH'] = '957b9ba29d14f52928d863d854278df8c749aaaca7f746d4127033ac4dfd5e8d6c3531433b2498daa03de77e925e7c09c55d0ef2'\n",
    "tchad_config_file = \"config/countries/tcd_adm0.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create country configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_config, geobb = create_area(tchad_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create IRI terciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_iri_terciles = iri_terciles_create(\n",
    "    country_config=country_config, \n",
    "    geobb=geobb,\n",
    "    only_dominant=False\n",
    ")\n",
    "ds_iri_tercile_dominant = calculate_dominant_tercile(ds_iri_terciles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CHIRPS terciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_chirps_terciles = chirps_terciles_create(\n",
    "    country_config=country_config, \n",
    "    geobb=geobb,\n",
    "    adapt_coordinates=True,\n",
    "    ds_ref=ds_iri_terciles\n",
    ")\n",
    "ds_chirps_tercile_dominant = calculate_dominant_tercile(ds_chirps_terciles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ECMWF terciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_ecmwf_terciles = ecmwf_terciles_create(\n",
    "    country_config=country_config, \n",
    "    geobb=geobb,\n",
    "    adapt_coordinates=True,\n",
    "    ds_ref=ds_iri_terciles,\n",
    ")\n",
    "ds_ecmwf_tercile_dominant = calculate_dominant_tercile(ds_ecmwf_terciles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt coordinates for IRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_iri_tercile_dominant = ds_iri_tercile_dominant.sel(latitude=ds_ecmwf_tercile_dominant.latitude)\n",
    "ds_iri_tercile_dominant = ds_iri_tercile_dominant.sel(longitude=ds_ecmwf_tercile_dominant.longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets for visualisation terciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ecmwf_vis = xr.where(\n",
    "    ds_ecmwf_tercile_dominant.dominant_terc=='upper',\n",
    "    ds_ecmwf_tercile_dominant.terc_prob,\n",
    "    -ds_ecmwf_tercile_dominant.terc_prob\n",
    ")\n",
    "\n",
    "ds_ecmwf_vis = xr.where(\n",
    "    ds_ecmwf_tercile_dominant.dominant_terc=='middle',\n",
    "    0,\n",
    "    ds_ecmwf_vis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_iri_vis = xr.where(\n",
    "    ds_iri_tercile_dominant.dominant_terc=='upper',\n",
    "    ds_iri_tercile_dominant.terc_prob,\n",
    "    -ds_iri_tercile_dominant.terc_prob\n",
    ")\n",
    "\n",
    "ds_iri_vis = xr.where(\n",
    "    ds_iri_tercile_dominant.dominant_terc=='middle',\n",
    "    0,\n",
    "    ds_iri_vis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chirps_vis = xr.where(\n",
    "    ds_chirps_tercile_dominant.dominant_terc=='upper',\n",
    "    ds_chirps_tercile_dominant.terc_prob,\n",
    "    -ds_chirps_tercile_dominant.terc_prob\n",
    ")\n",
    "\n",
    "ds_chirps_vis = xr.where(\n",
    "    ds_chirps_tercile_dominant.dominant_terc=='middle',\n",
    "    0,\n",
    "    ds_chirps_vis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize terciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_plot = ds_ecmwf_vis.hvplot(\n",
    "    groupby='time',\n",
    "    widget_type='scrubber', \n",
    "    x='longitude', \n",
    "    y='latitude',\n",
    "    coastline=True,\n",
    "    features=['borders'], \n",
    "    clim=(-1, 1),\n",
    "    geo=True,\n",
    "    widget_location='bottom',\n",
    "    cmap='BrBG',\n",
    "    width=600, height=500,\n",
    "    label='ECMWF,'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "map_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map_plot = ds_ecmwf_vis.hvplot(\n",
    "    groupby='time',\n",
    "    widget_type='scrubber', \n",
    "    x='longitude', \n",
    "    y='latitude',\n",
    "    coastline=True,\n",
    "    features=['borders'], \n",
    "    clim=(-1, 1),\n",
    "    geo=True,\n",
    "    widget_location='bottom',\n",
    "    cmap='BrBG',\n",
    "    width=600, height=500,\n",
    "    label='ECMWF,'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "map_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_plot = ds_iri_vis.hvplot(\n",
    "    groupby='time',\n",
    "    widget_type='scrubber', \n",
    "    x='longitude', \n",
    "    y='latitude',\n",
    "    coastline=True,\n",
    "    features=['borders'], \n",
    "    clim=(-1, 1),\n",
    "    geo=True,\n",
    "    widget_location='bottom',\n",
    "    cmap='BrBG',\n",
    "    width=600, height=500,\n",
    "    label='IRI,'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "map_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_plot = ds_chirps_vis.hvplot(\n",
    "    groupby='time',\n",
    "    widget_type='scrubber', \n",
    "    x='longitude', \n",
    "    y='latitude',\n",
    "    coastline=True,\n",
    "    features=['borders'], \n",
    "    clim=(-1, 1),\n",
    "    geo=True,\n",
    "    widget_location='bottom',\n",
    "    cmap='BrBG',\n",
    "    width=600, height=500,\n",
    "    label='CHIRPS,'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "map_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate metrics: accuracy and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points under which predicted and true dataset will not be compared and accuracy and F1 score \n",
    "# will be set to zero\n",
    "tolerance = 4 \n",
    "\n",
    "# Initiate score array\n",
    "score_array = {}\n",
    "\n",
    "# Loop over metrics\n",
    "for metrics in ['accuracy', 'f1 score']:\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "    # Loop over forecast products\n",
    "    for d, data in enumerate(['iri', 'ecmwf']):\n",
    "        \n",
    "        print(data)\n",
    "\n",
    "        # Loop over relevant seasons\n",
    "        for s, season in enumerate(['MJJ', 'JJA', 'JAS', 'ASO']):\n",
    "\n",
    "            print(season)\n",
    "\n",
    "            # Choose dataset\n",
    "            if data=='iri':\n",
    "                forecast_dataset = ds_iri_tercile_dominant.copy()\n",
    "            else:\n",
    "                forecast_dataset = ds_ecmwf_tercile_dominant.copy()\n",
    "\n",
    "            # Restrict dataset to season\n",
    "            forecast_dataset = forecast_dataset.sel(time=forecast_dataset['time'].str.contains(season))\n",
    "\n",
    "            # Restrict chirps dataset to time points (season-year) present in the forecast dataset\n",
    "            chirps_dataset = chirps_dataset.sel(\n",
    "                time=ds_chirps_tercile_dominant['time'].isin(forecast_dataset['time'])\n",
    "            )\n",
    "\n",
    "            # Create masks for chirps and forecast (NaN values are replaced by -999)\n",
    "            mask_chirps = np.asarray(chirps_dataset.terc_prob.fillna(-999))\n",
    "            mask_forecast = forecast_dataset.terc_prob.fillna(-999)\n",
    "\n",
    "            # Threshold for tercile probabilities\n",
    "            threshold_num_list = [np.nan, np.nan]+[t for t in np.arange(0.3, 0.9, 0.1)]\n",
    "            threshold_str_list = [\n",
    "                'All terciles considered', \n",
    "                'Only below considered: no threshold'\n",
    "            ]+[f'Only below considered: threshold {t:.1f}' for t in threshold_num_list[2:]]\n",
    "\n",
    "            # Loop over thresholds\n",
    "            for t, (threshold, threshold_label) in enumerate(zip(threshold_num_list, threshold_str_list)):\n",
    "\n",
    "                # 'All terciles considered': here the metrics will be calculated based on\n",
    "                # - success: same dominant tercile\n",
    "                # - failure: different dominant tercile\n",
    "                if t==0:\n",
    "                    forecast = forecast_dataset.dominant_terc\n",
    "                    chirps = chirps_dataset.dominant_terc\n",
    "                # 'Only below considered: no threshold': here the metrics will be calculated based on\n",
    "                # - success: both observation and forecast have dominant tercile 'lower'\n",
    "                # - failure: both observation and forecast don't have dominant tercile 'lower' \n",
    "                elif t==1:\n",
    "                    forecast = forecast_dataset.dominant_terc.where(\n",
    "                        forecast_dataset.dominant_terc=='lower', \n",
    "                        'not_lower'\n",
    "                    )\n",
    "                    chirps = chirps_dataset.dominant_terc.where(\n",
    "                        chirps_dataset.dominant_terc=='lower', \n",
    "                        'not_lower'\n",
    "                    )\n",
    "                # 'Only below considered: threshold ...': here the metrics will be calculated based on\n",
    "                # - success: both observation and forecast have dominant tercile 'lower', and the terc.\n",
    "                #            probability is higher than the threshold\n",
    "                # - failure: both observation and forecast don't have dominant tercile 'lower', or they have\n",
    "                #            dominant tercile 'lower' but with probability lower than the threshold\n",
    "                else:\n",
    "                    forecast = xr.where(\n",
    "                        (forecast_dataset.terc_prob>threshold) & (forecast_dataset.dominant_terc=='lower'), \n",
    "                        1, \n",
    "                        0\n",
    "                    )\n",
    "                    chirps = xr.where(\n",
    "                        chirps_dataset.dominant_terc=='lower', \n",
    "                        1, \n",
    "                        0\n",
    "                    )\n",
    "\n",
    "                # Reapply the mask previously calculated\n",
    "                forecast = forecast.where((mask_chirps!=-999) & (mask_forecast!=-999))\n",
    "                chirps = chirps.where((mask_chirps!=-999) & (mask_forecast!=-999))\n",
    "\n",
    "                # Create score array\n",
    "                score = np.empty((np.shape(chirps)[1:]))\n",
    "                score[:] = np.nan\n",
    "\n",
    "                # Loop over latitude and longitude\n",
    "                for i in range(np.shape(chirps)[1]):\n",
    "                    for j in range(np.shape(chirps)[2]):\n",
    "                        \n",
    "                        # Read values of lon and lat\n",
    "                        latitude = forecast.latitude.values[i]\n",
    "                        longitude = forecast.longitude.values[j]\n",
    "                        \n",
    "                        # Create time series for predicted (forecast) and true (observations)\n",
    "                        y_pred = forecast.sel(latitude=latitude, longitude=longitude).values\n",
    "                        y_true = chirps.sel(latitude=latitude, longitude=longitude).values\n",
    "                        \n",
    "                        # Pair time series, and exclude nan values (this is done to keep only non-nan values\n",
    "                        # and return nan in case there are not many comparisons)\n",
    "                        y_pair = [(x, y) for (x,y) in zip(list(y_true), list(y_pred)) \\\n",
    "                                  if not pd.isna(x) and not pd.isna(y)]\n",
    "                        \n",
    "                        # If the number of pairs is lower than the tolerance, assign nan to the metric\n",
    "                        if len(y_pair)<tolerance:\n",
    "                            score[i, j] = np.nan\n",
    "                        else:\n",
    "                            # Re-extract time series\n",
    "                            y_true = [p[0] for p in y_pair]\n",
    "                            y_pred = [p[1] for p in y_pair]\n",
    "                            \n",
    "                            # Calculate metrics\n",
    "                            if metrics == 'accuracy':\n",
    "                                score[i, j] = accuracy_score(y_true, y_pred)\n",
    "                            else:\n",
    "                                score[i, j] = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "                # Initialise score dataArray\n",
    "                score_thre = chirps.isel(time=0).drop('time').copy()\n",
    "                \n",
    "                # Assign score array to variable of the dataArray\n",
    "                score_thre.data = score.copy()\n",
    "                \n",
    "                # Expand dimensions of the dataArray, to include other coordinates. This is done to be able\n",
    "                # to create the final dataArray\n",
    "                score_thre = score_thre.expand_dims(['season', 'threshold', 'data'])\\\n",
    "                                       .assign_coords({\n",
    "                    'season': [season], \n",
    "                    'threshold': [threshold_label],\n",
    "                    'data': [data],\n",
    "                })\n",
    "\n",
    "                # At the first iteration, create a new dataArray, later concatenate the dataArray with the\n",
    "                # one created in this iteration\n",
    "                if t==0:\n",
    "                    score_season = score_thre.copy()\n",
    "                else:\n",
    "                    score_season = xr.concat([score_season, score_thre], dim='threshold')\n",
    "            \n",
    "            # At the first iteration, create a new dataArray, later concatenate the dataArray with the\n",
    "            # one created in this iteration\n",
    "            if s==0:\n",
    "                score_data = score_season.copy()\n",
    "            else:\n",
    "                score_data = xr.concat([score_data, score_season], dim='season')\n",
    "        \n",
    "        # At the first iteration, create a new dataArray, later concatenate the dataArray with the\n",
    "        # one created in this iteration\n",
    "        if d==0:\n",
    "            score_array[metrics] = score_data.copy()\n",
    "        else:\n",
    "            score_array[metrics] = xr.concat([score_array[metrics], score_data], dim='data')    \n",
    "\n",
    "# Transform dict of dataArrays in dataset, with two variables\n",
    "score_array_total = xr.Dataset(score_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dataset with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "for data in ['ECMWF', 'IRI']:\n",
    "    for score in ['Accuracy', 'F1 score']:\n",
    "        for season in score_array_total.season.values.tolist():\n",
    "            dataset = gv.Dataset(\n",
    "                data=score_array_total.sel(season=season, data=data.lower()).drop(['season', 'data']), \n",
    "                kdims=['longitude', 'latitude', 'threshold'],\n",
    "                vdims=score.lower(),\n",
    "                label=f'Score: {score}, Dataset: {data},\\n'+f'Season: {season},',\n",
    "                crs=ccrs.PlateCarree()\n",
    "            )\n",
    "            images = dataset.to(gv.Image)\n",
    "            display(images.opts(cmap='viridis', colorbar=True, width=600, height=500) * gf.borders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.google.com/drawings/d/1CB504-oanD6T2KRVrC6-pwj8cHT_ygc300PKrawQYCw/edit\n",
    "\n",
    "- Check code for accuracy and F1 score\n",
    "- Create polygon based on aggregation (Sahel belt)\n",
    "- Aggregate xarrays based on polygon\n",
    "- Produce plot\n",
    "- Add other lead times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ocha-anticipy-user]",
   "language": "python",
   "name": "conda-env-ocha-anticipy-user-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3a84c259f6b58d590ef7c1b04c905dbca7434292bde8564a04bf3fac40c0c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
